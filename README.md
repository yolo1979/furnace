# ğŸ”¥ Furnace

**Balance â€¢ Budget â€¢ Tally**  
*Track and control AI agent costs in real time â€” before your credits vanish.*

---

## ğŸ“– Overview

AI agents are powerful, but invisible costs can burn through your credits faster than expected. **Furnace** gives you **real-time cost visibility**, letting you:

- âœ… Set a budget per ask  
- âœ… Estimate token costs before running  
- âœ… Track burns live with a tally (in-app + menu bar widget)  
- âœ… Send budget alerts to Slack via secure **Descope Outbound Apps** (no hardcoded tokens)

---

## ğŸš¨ The Problem
Invisible AI spend â€” tokens, credits, and cycles vanish during agent runs with no visibility.  
Teams discover the damage only afterwards, when credits are already burned.

## ğŸ’¡ The Solution
**Furnace is the fire alarm for runaway AI spend.**  
It shows balance, budget, and live burn rate in real time â€” with alerts before the fire gets out of control.  

And this isnâ€™t just about OpenAI. Nearly every modern AI platform charges in **tokens, credits, or usage hours**. Thatâ€™s why Furnace is designed to work universally.

---

Problem Statement & Objective

In todayâ€™s AI-driven world, almost every major platform â€” from OpenAI to Replit to Manus â€” uses token- or credit-based billing models. While these systems make AI more accessible, they share a critical weakness:
	â€¢	Invisible Spending â€“ users only discover what theyâ€™ve burned after the fact.
	â€¢	Budget Shock â€“ developers blow through credits unexpectedly, with no real-time awareness.
	â€¢	Lack of Controls â€“ thereâ€™s no universal tool to set budgets, track burn rate, or get alerts across providers.

This issue is not limited to advanced teams. From indie developers experimenting with prompts, to startups running agentic workflows, to students on free-tier credits â€” the lack of real-time spend visibility is a universal problem.

Objective:
Our project, ğŸ”¥ Furnace, tackles this problem by giving users live awareness and control of AI spend â€” before, during, and after running their agents. Furnace acts like a â€œburn meterâ€ for AI usage, ensuring you can set a budget, see spend as it happens, and get alerts before you cross the line.

â¸»

Methodology

We designed Furnace to work as a lightweight layer on top of existing AI providers. The methodology is simple:
	1.	Budget Setting â€“ User sets an initial balance and budget cap.
	2.	Live Tally â€“ Furnace tracks burned tokens/credits in real-time, showing a clear tally of whatâ€™s been spent and what remains.
	3.	Estimation Engine â€“ For OpenAI, Furnace calculates expected costs using official per-token pricing. For providers without pricing APIs (e.g. Replit), users can log manual burn steps.
	4.	Alerts & Notifications â€“ When spend approaches 80%, Furnace sends a Slack alert (via secure Descope integration). At 100%, it stops the burn automatically.
	5.	Cross-Platform Access â€“ Users can view the tally:
	â€¢	In the web dashboard (Next.js, Vercel)
	â€¢	In a pop-out tally window
	â€¢	In the Mac menu bar app (Electron menubar with ğŸ”¥ icon)

This ensures constant visibility â€” wherever the user works.

â¸»

Scope of the Solution
	â€¢	Universal Application â€“ Works with any credit/token-based AI service (OpenAI, Replit, Manus, Anthropic, etc.).
	â€¢	Secure by Design â€“ Integrates Slack via Descope Outbound Apps, ensuring no hardcoded tokens and frictionless user auth.
	â€¢	Scalable â€“ Current prototype supports single-user budgets, but the same architecture can extend to team dashboards, shared credits, and multi-provider usage.
	â€¢	Innovative Edge â€“ Adds features no provider offers natively: live burn meter, auto-stop at budget, and multi-platform visibility.

â¸»

Additional Details
	â€¢	Tech Stack: Next.js (frontend), Vercel (hosting), Electron (menubar app), Slack API, Descope (secure auth).
	â€¢	Innovation Highlights:
	â€¢	Auto-Burn Mode â€“ simulates ongoing agent runs until budget is exhausted.
	â€¢	Cross-Runtime Tally Sync â€“ syncs burn data between browser, menubar, and Slack.
	â€¢	Slack Alerts â€“ seamless notifications without manual token handling.
	â€¢	Future Roadmap:
	â€¢	Multi-provider adapters for Anthropic, Cohere, and beyond.
	â€¢	Shared team budgets with role-based access.
	â€¢	Browser extension for inline burn tracking during prompt testing.


## ğŸ”‘ Who Needs Furnace?
Furnace isnâ€™t tied to one provider â€” itâ€™s built for **any AI service that bills by credits, tokens, or usage**.  
Today, nearly every major platform already uses this model:

### **AI Model Providers**
- OpenAI â€“ credits & token-based pricing (gpt-4, gpt-4o, gpt-4o-mini, etc.).  
- Anthropic (Claude) â€“ token-based pricing.  
- Mistral â€“ API usage billed per token.  
- Cohere â€“ API credits/token usage.  

### **Developer Platforms**
- Replit â€“ cycles (credits) consumed per agent run / AI request.  
- Manus â€“ token-based plan for agent executions.  
- Hugging Face Inference â€“ credit-based usage (per inference call).  

### **Creative / Generative Tools**
- MidJourney â€“ â€œfast hoursâ€ credit system.  
- Runway ML â€“ credits for video generation.  
- Stable Diffusion APIs (Replicate, Stability AI) â€“ per-credit inference.  

ğŸ”¥ **The point:** Whether youâ€™re coding, prompting, or generating media, **credits are the new currency of AI** â€” and they disappear fast.  
Furnace makes sure you can *see, track, and cap the burn* before itâ€™s too late.

---

## ğŸ¥ Demo Video

ğŸ“º [Watch the 5-minute demo on Youtube
â¡ï¸ [Furnace Demo on Youtube] ( https://www.youtube.com/watch?v=4ig3cwXcSZk)

The demo shows:  
1. Setting a budget and burning step-by-step  
2. Live tally updating in the dashboard + widget  
3. Slack alerts firing when budget thresholds are hit  

---

## ğŸš€ Live App

ğŸ”— [Deployed on Vercel](https://furnace-one.vercel.app)

---

## ğŸ› ï¸ Tech Stack

- [Next.js](https://nextjs.org/) â€” Frontend + API routes  
- [Vercel](https://vercel.com/) â€” Hosting & environment management  
- [Electron](https://www.electronjs.org/) â€” macOS menubar widget  
- [Slack API](https://api.slack.com/) â€” Real-time notifications  
- [Descope](https://www.descope.com/) â€” Secure outbound app integration  
- [BroadcastChannel + localStorage] â€” Cross-window live tally sync  

---

## ğŸ“‚ Repo Structure
/components
FurnaceAsk.jsx      â†’ main dashboard component
/pages
index.js            â†’ homepage
tally.js            â†’ live tally popout
/api
tally/save.js     â†’ save tally snapshot
tally/latest.js   â†’ return latest tally
slack/post.js     â†’ send Slack alerts
/styles
globals.css         â†’ clean Apple-style theme

---

## ğŸ”® Future Roadmap

Furnace is just the start. Hereâ€™s whatâ€™s next:

- **Multi-provider adapters** â†’ direct API hooks for OpenAI, Anthropic, Replit, Hugging Face, and more.  
- **Automatic cost estimates** â†’ detect model + token size automatically, no manual input needed.  
- **Team dashboards** â†’ shared budget views with role-based access and per-user limits.  
- **Predictive alerts** â†’ estimate *time-to-burn* based on live usage trends.  
- **Export & reports** â†’ generate weekly/monthly usage reports for finance & ops teams.  
- **Cross-platform support** â†’ Windows/Linux tray apps, mobile companion app for spend alerts.  

---

## ğŸ‘¥ Team

Built by **Padraig Oâ€™Brien** (solo).  
Part of the [Global MCP Hackathon](https://www.descope.com/sign-up-global-mcp-hackathon).

---

## ğŸ“œ License

MIT License â€” free to use, modify, and extend.  

---

ğŸ”¥ *Furnace: the fire alarm for runaway AI spend.*